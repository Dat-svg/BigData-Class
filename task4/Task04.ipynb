{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHFNs96HUZlm",
        "outputId": "507038bd-423b-4d4b-f1db-70da32ebf6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Kết nối Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "! wget -q https://archive.apache.org/dist/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz\n",
        "# ! cp /content/drive/MyDrive/midterm_MMDS/pyspark/spark-3.5.4-bin-hadoop3.tgz .\n",
        "# ! cp /content/drive/MyDrive/MMDS/spark/spark-3.5.4-bin-hadoop3.tgz .\n",
        "\n",
        "! tar xf spark-3.5.4-bin-hadoop3.tgz\n",
        "! pip install -q findspark"
      ],
      "metadata": {
        "id": "PoTKoH2WUpwn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! du -sh spark-3.5.4-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "T-I3qhMvU-XU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf394bb-2269-4b9e-e059-a40a1d8e8624"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "383M\tspark-3.5.4-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import pyspark as spark\n",
        "\n",
        "findspark.init()\n",
        "print(spark.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abhq7yTCVBiD",
        "outputId": "2759ad7c-6f92-4688-dc53-4616806f6e4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Distributed PageRank\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"SparkSession đã được khởi tạo thành công.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejpmmbmiVxvi",
        "outputId": "3d9c9a3f-d5d4-4934-b1f3-99a1616dbcc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession đã được khởi tạo thành công.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, lit, sum as sum_agg, abs, row_number\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "JTVhtvdkXjs7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(spark, df):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu: ánh xạ URL thành chỉ số và tạo DataFrame cạnh.\n",
        "\n",
        "    Parameters:\n",
        "    spark (SparkSession): SparkSession\n",
        "    df (DataFrame): DataFrame chứa cột src và dst\n",
        "\n",
        "    Returns:\n",
        "    tuple: (edges_df, n, url_to_idx, idx_to_url)\n",
        "    \"\"\"\n",
        "    # Lấy danh sách URL duy nhất và gán chỉ số\n",
        "    urls_df = df.select(\"src\").union(df.select(\"dst\")).distinct().withColumnRenamed(\"src\", \"url\")\n",
        "    window = Window.orderBy(\"url\")\n",
        "    url_idx_df = urls_df.withColumn(\"idx\", row_number().over(window) - 1)\n",
        "\n",
        "    # Join để ánh xạ src và dst thành chỉ số\n",
        "    edges_df = df.join(url_idx_df.withColumnRenamed(\"url\", \"src\"), \"src\", \"left\") \\\n",
        "                 .withColumnRenamed(\"idx\", \"src_idx\") \\\n",
        "                 .join(url_idx_df.withColumnRenamed(\"url\", \"dst\"), \"dst\", \"left\") \\\n",
        "                 .withColumnRenamed(\"idx\", \"dst_idx\") \\\n",
        "                 .select(\"src_idx\", \"dst_idx\") \\\n",
        "                 .filter(col(\"src_idx\").isNotNull() & col(\"dst_idx\").isNotNull())\n",
        "\n",
        "    # Đếm số node (số hàng trong url_idx_df)\n",
        "    n = url_idx_df.count()\n",
        "\n",
        "\n",
        "    print(f\"Số trang web (node): {n}\")\n",
        "    print(f\"Số liên kết (edge): {edges_df.count()}\")\n",
        "    print(f\"Kiểu của n: {type(n)}\")\n",
        "\n",
        "    return edges_df, n, {}, {}"
      ],
      "metadata": {
        "id": "8xFyxvziWDof"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_out_degree(spark, edges_df, n):\n",
        "    \"\"\"\n",
        "    Tính số liên kết ra và xử lý dead ends.\n",
        "\n",
        "    Parameters:\n",
        "    spark (SparkSession): SparkSession\n",
        "    edges_df (DataFrame): DataFrame chứa cạnh\n",
        "    n (int): Số node\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: out_degree_df chứa số liên kết ra\n",
        "    \"\"\"\n",
        "    # Đảm bảo n là int\n",
        "    n = int(n)\n",
        "\n",
        "    # Tính out-degree\n",
        "    out_degree_df = edges_df.groupBy(\"src_idx\").agg(count(\"dst_idx\").alias(\"out_degree\"))\n",
        "\n",
        "    # Tạo danh sách tất cả node\n",
        "    all_nodes_df = spark.range(n).select(col(\"id\").alias(\"node_idx\"))\n",
        "\n",
        "    # Kết hợp để xử lý dead ends\n",
        "    out_degree_df = all_nodes_df.join(out_degree_df,\n",
        "                                      all_nodes_df.node_idx == out_degree_df.src_idx,\n",
        "                                      \"left_outer\") \\\n",
        "                                .select(\"node_idx\", col(\"out_degree\").alias(\"out_degree\")) \\\n",
        "                                .fillna({\"out_degree\": 0})\n",
        "\n",
        "    print(\"Đã tính số liên kết ra cho tất cả các node.\")\n",
        "\n",
        "    return out_degree_df"
      ],
      "metadata": {
        "id": "HSKVqQZGWWt9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pagerank(spark, edges_df, n, out_degree_df, d=0.85, max_iter=50, tol=1e-4):\n",
        "    \"\"\"\n",
        "    Tính PageRank phân tán, tránh lỗi unhashable type Column.\n",
        "\n",
        "    Parameters:\n",
        "    spark (SparkSession): SparkSession\n",
        "    edges_df (DataFrame): DataFrame chứa cạnh\n",
        "    n (int): Số node\n",
        "    out_degree_df (DataFrame): DataFrame chứa out-degree\n",
        "    d (float): Damping factor\n",
        "    max_iter (int): Số lần lặp tối đa\n",
        "    tol (float): Ngưỡng hội tụ\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: DataFrame chứa (node_idx, pagerank)\n",
        "    \"\"\"\n",
        "    # Đảm bảo n là int\n",
        "    n = int(n)\n",
        "\n",
        "    # Khởi tạo vector PageRank\n",
        "    r = spark.createDataFrame([(i, 1.0 / n) for i in range(n)], [\"node_idx\", \"pagerank\"]).cache()\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        # Tính đóng góp, sử dụng join với out_degree_df\n",
        "        contrib_df = edges_df.join(r, edges_df.src_idx == r.node_idx, \"inner\") \\\n",
        "                            .join(out_degree_df, edges_df.src_idx == out_degree_df.node_idx, \"inner\") \\\n",
        "                            .select(edges_df.dst_idx,\n",
        "                                    (d * col(\"pagerank\") / col(\"out_degree\")).alias(\"contrib\")) \\\n",
        "                            .where(col(\"out_degree\") > 0)\n",
        "\n",
        "        # Gộp đóng góp và thêm teleport\n",
        "        new_r = contrib_df.groupBy(\"dst_idx\").agg(sum_agg(\"contrib\").alias(\"sum_contrib\")) \\\n",
        "                         .withColumn(\"pagerank\", col(\"sum_contrib\") + lit((1 - d) / n)) \\\n",
        "                         .select(col(\"dst_idx\").alias(\"node_idx\"), \"pagerank\")\n",
        "\n",
        "        # Kết hợp với tất cả node để xử lý node không nhận liên kết\n",
        "        all_nodes_df = spark.range(n).select(col(\"id\").alias(\"node_idx\"))\n",
        "        new_r = all_nodes_df.join(new_r, all_nodes_df.node_idx == new_r.node_idx, \"left_outer\") \\\n",
        "                           .select(all_nodes_df.node_idx,\n",
        "                                   col(\"pagerank\").alias(\"pagerank\")) \\\n",
        "                           .fillna({\"pagerank\": (1 - d) / n}).cache()\n",
        "\n",
        "        # Chuẩn hóa tổng PageRank (sử dụng approx sum để tránh collect nếu cần)\n",
        "        total_pr_df = new_r.agg(sum_agg(\"pagerank\").alias(\"total\"))\n",
        "        total_pr = total_pr_df.first()[\"total\"]  # first() thay collect()[0]\n",
        "\n",
        "        new_r = new_r.withColumn(\"pagerank\", col(\"pagerank\") / lit(total_pr))\n",
        "\n",
        "        # Kiểm tra hội tụ (sử dụng first() thay collect())\n",
        "        diff_df = new_r.join(r, \"node_idx\", \"inner\") \\\n",
        "                      .withColumn(\"diff\", abs(col(\"new_r.pagerank\") - col(\"r.pagerank\"))) \\\n",
        "                      .agg(sum_agg(\"diff\").alias(\"l1_norm\"))\n",
        "        diff = diff_df.first()[\"l1_norm\"]\n",
        "\n",
        "        print(f\"Iteration {iteration + 1}, L1 norm: {diff:.6f}\")\n",
        "\n",
        "        # Unpersist cũ, cập nhật r\n",
        "        r.unpersist()\n",
        "        r = new_r\n",
        "        if diff < tol:\n",
        "            print(f\"Hội tụ sau {iteration + 1} lần lặp\")\n",
        "            break\n",
        "\n",
        "    if iteration == max_iter - 1:\n",
        "        print(f\"Đạt số lần lặp tối đa ({max_iter})\")\n",
        "\n",
        "    r.unpersist()\n",
        "    return new_r\n"
      ],
      "metadata": {
        "id": "OePEEMTiXrxv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(pagerank_df, idx_to_url, top_n=10, d=0.85, n=4622):\n",
        "    \"\"\"\n",
        "    Hiển thị top trang web và thống kê teleport.\n",
        "\n",
        "    Parameters:\n",
        "    pagerank_df (DataFrame): DataFrame chứa (node_idx, pagerank)\n",
        "    idx_to_url (dict): Ánh xạ từ chỉ số sang URL\n",
        "    top_n (int): Số trang hiển thị\n",
        "    d (float): Damping factor\n",
        "    n (int): Số node\n",
        "    \"\"\"\n",
        "    n = int(n)\n",
        "\n",
        "    # Tính teleport value\n",
        "    teleport_value = (1 - d) / n\n",
        "\n",
        "    # Lấy top N trực tiếp từ Spark\n",
        "    top_df = pagerank_df.orderBy(col(\"pagerank\").desc()).limit(top_n)\n",
        "    top_rows = top_df.collect()  # Thu thập chỉ top_n hàng\n",
        "\n",
        "    # Tính tổng và dead ends phân tán\n",
        "    total_pr_df = pagerank_df.agg(sum_agg(\"pagerank\").alias(\"total\"))\n",
        "    total_pr = total_pr_df.first()[\"total\"]\n",
        "\n",
        "    dead_ends_df = pagerank_df.withColumn(\"is_dead_end\", abs(col(\"pagerank\") - lit(teleport_value)) < 1e-10)\n",
        "    dead_ends_count = dead_ends_df.filter(col(\"is_dead_end\")).count()\n",
        "\n",
        "    print(f\"Nodes relying only on teleport: {dead_ends_count}\")\n",
        "\n",
        "    print(\"\\nTop trang web theo PageRank:\")\n",
        "    for row in top_rows:\n",
        "        url = idx_to_url.get(row[\"node_idx\"])\n",
        "        print(f\"URL: {url}\\nScore: {row['pagerank']:.6f}\\n\")\n",
        "\n",
        "    print(f\"Tổng PageRank: {total_pr:.4f}\")"
      ],
      "metadata": {
        "id": "Up8hqjIjX0Wv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class DistributedPageRank:\n",
        "    def __init__(self, csv_path, driver_memory=\"4g\", executor_memory=\"4g\"):\n",
        "        if not os.path.exists(csv_path):\n",
        "            raise FileNotFoundError(f\"File {csv_path} không tồn tại\")\n",
        "\n",
        "        self.spark = SparkSession.builder \\\n",
        "            .appName(\"Distributed PageRank\") \\\n",
        "            .config(\"spark.driver.memory\", driver_memory) \\\n",
        "            .config(\"spark.executor.memory\", executor_memory) \\\n",
        "            .getOrCreate()\n",
        "\n",
        "        self.csv_path = csv_path\n",
        "        self.df = self.spark.read.csv(csv_path, header=True)\n",
        "        if not all(col in self.df.columns for col in [\"src\", \"dst\"]):\n",
        "            raise ValueError(\"File CSV phải có cột 'src' và 'dst'\")\n",
        "\n",
        "        self.n = 0\n",
        "        self.edges_df = None\n",
        "        self.url_to_idx = {}\n",
        "        self.idx_to_url = {}\n",
        "        self.out_degree_df = None\n",
        "        self.pagerank_df = None\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        self.edges_df, self.n, self.url_to_idx, self.idx_to_url = preprocess_data(self.spark, self.df)\n",
        "\n",
        "    def compute_out_degree(self):\n",
        "        self.out_degree_df = compute_out_degree(self.spark, self.edges_df, self.n)\n",
        "\n",
        "    def compute_pagerank(self, d=0.85, max_iter=15, tol=1e-6):\n",
        "        self.pagerank_df = compute_pagerank(self.spark, self.edges_df, self.n,\n",
        "                                          self.out_degree_df, d, max_iter, tol)\n",
        "\n",
        "    def display_results(self, top_n=10):\n",
        "        if self.pagerank_df is None:\n",
        "            print(\"Chưa tính PageRank. Vui lòng chạy compute_pagerank() trước.\")\n",
        "            return\n",
        "        display_results(self.pagerank_df, self.idx_to_url, top_n, d=0.85, n=self.n)\n",
        "\n",
        "    def save_results(self, output_path):\n",
        "        self.pagerank_df.write.csv(f\"{output_path}/pagerank\", mode=\"overwrite\")\n",
        "        pd.DataFrame(self.idx_to_url.items(), columns=[\"idx\", \"url\"]) \\\n",
        "          .to_csv(f\"{output_path}/url_mapping.csv\", index=False)\n",
        "        print(f\"Kết quả đã được lưu tại {output_path}\")\n",
        "\n",
        "    def cleanup(self):\n",
        "        if self.edges_df:\n",
        "            self.edges_df.unpersist()\n",
        "        if self.pagerank_df:\n",
        "            self.pagerank_df.unpersist()\n",
        "        if self.out_degree_df:\n",
        "            self.out_degree_df.unpersist()\n",
        "        self.spark.stop()\n",
        "        print(\"SparkSession đã được dừng.\")"
      ],
      "metadata": {
        "id": "YuDQH1xmX9jq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn\n",
        "csv_path = \"/content/drive/MyDrive/MMDS/Final/source/dataset_link_web1.csv\"\n",
        "output_path = \"/content/drive/MyDrive/MMDS/Final/output\"\n",
        "\n",
        "pr = DistributedPageRank(csv_path)\n",
        "pr.preprocess_data()\n",
        "pr.compute_out_degree()\n",
        "pr.compute_pagerank(d=0.85, max_iter=15, tol=1e-6)\n",
        "pr.display_results(top_n=10)\n",
        "pr.save_results(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqDGl8M7a_fu",
        "outputId": "2e5e9ed9-0fc3-416f-a2da-064fac0b380f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số trang web (node): 2479\n",
            "Số liên kết (edge): 39856\n",
            "Kiểu của n: <class 'int'>\n",
            "Đã tính số liên kết ra cho tất cả các node.\n",
            "Iteration 1, L1 norm: 1.506295\n",
            "Iteration 2, L1 norm: 0.573540\n",
            "Iteration 3, L1 norm: 0.154672\n",
            "Iteration 4, L1 norm: 0.056789\n",
            "Iteration 5, L1 norm: 0.021351\n",
            "Iteration 6, L1 norm: 0.014512\n",
            "Iteration 7, L1 norm: 0.009896\n",
            "Iteration 8, L1 norm: 0.007265\n",
            "Iteration 9, L1 norm: 0.005205\n",
            "Iteration 10, L1 norm: 0.003763\n",
            "Iteration 11, L1 norm: 0.002707\n",
            "Iteration 12, L1 norm: 0.001950\n",
            "Iteration 13, L1 norm: 0.001403\n",
            "Iteration 14, L1 norm: 0.001009\n",
            "Iteration 15, L1 norm: 0.000726\n",
            "Đạt số lần lặp tối đa (15)\n",
            "Nodes relying only on teleport: 0\n",
            "\n",
            "Top trang web theo PageRank:\n",
            "URL: https://it.tdtu.edu.vn/\n",
            "Score: 0.041608\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/en\n",
            "Score: 0.038987\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/vien-chuc\n",
            "Score: 0.032443\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/sinh-vien\n",
            "Score: 0.032443\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/tin-tuc/tuyen-dung\n",
            "Score: 0.031879\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/gioi-thieu\n",
            "Score: 0.031807\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/giao-duc\n",
            "Score: 0.031786\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/tin-tuc\n",
            "Score: 0.031731\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/tin-tuc-khoa\n",
            "Score: 0.031536\n",
            "\n",
            "URL: https://it.tdtu.edu.vn/khoa-hoc-cong-nghe\n",
            "Score: 0.031245\n",
            "\n",
            "Tổng PageRank: 1.0000\n",
            "Kết quả đã được lưu tại /content/drive/MyDrive/MMDS/Final/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irEKIBtAQ5K-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}